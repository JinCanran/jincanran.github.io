---
layout:     post
title:      "Paper Reading Note"
subtitle:   "ApproxANN: An Approximate Computing Framework for Artificial Neural Network"
date:       2016-11-02
author:     "Jin"
header-img: "img/post-bg-2015.jpg"
tags:
    - Neural Network
    - Approximate Computing
    - Paper Reading Notes
---

>  Zhang Q, Wang T, Tian Y, et al. ApproxANN: an approximate computing framework for artificial neural network[C]//Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition. EDA Consortium, 2015: 701-706.

## ABSTRACT

- ApproxANN characterizes ç¥ç»å…ƒå¯¹è¾“å‡ºè´¨é‡çš„å½±å“ï¼Œç”¨é«˜æ•ˆçš„æ–¹å¼
- ç„¶åå†³å®š how to approximate the computation and memory accesses of certain less critical neurons to achieve the maximum energy efficiency gain under a given quality constraint.

-----

## 1. INTRODUCTION

- ä¸»è¦å·¥ä½œï¼š
1. åœ¨å­˜å‚¨è®¿é—®å’Œè®¡ç®—è¿‡ç¨‹éƒ½è€ƒè™‘äº†approximationï¼Œæ¯”ç°å­˜çš„é‚£äº›æ–¹æ³•æ›´æœ‰æ•ˆ[5,8]
2. **Theoretical neuron criticality analysis technique**, which can be efficiently applied to neural networks with any topologies
3. **New optimization procedure** for approximate ANN construction, wherein error-tolerance capability and energy consumption are jointly considered to achieve the optimized energy savings under a given quality constraint.



------

## 2. PRELIMINARIES

- äººå·¥ç¥ç»ç½‘ç»œç®€ä»‹
- ç›¸å…³å·¥ä½œ
    - [5] ç¬¬ä¸€ä¸ªç”¨è¿‘ä¼¼ä¹˜æ³•å™¨åœ¨äººå·¥ç¥ç»ç½‘ç»œé‡Œ
    - [8] æœ‰è¿‡ä¸€ç¯‡AxNNçš„paperä½†æ˜¯æœ‰ä¸€äº›å¯ä»¥æ”¹è¿›ï¼Œæœ¬æ–‡åŸºæœ¬åŸºäºæ­¤
        - æœ€ä¸»è¦æ˜¯AxNNçš„cirticalityåˆ¤æ–­ç»“æœå¯èƒ½ä¸é‚£ä¹ˆä»¤äººä¿¡æœï¼Œ*åŸå› æ¶‰åŠWçš„çŸ©é˜µçš„ç§©ï¼Œæš‚æ—¶æ²¡çœ‹æ‡‚*
> çœ‹å®Œäº†ï¼Œæœ‰ç©ºå†å†™Reading Note 

-------

## 3. PROPOSED DESIGN METHODOLOGY  

### 3.1 Neuron Criticality Analysis
- Critical & Resilient ï¼š ç¥ç»å…ƒå¾®å°çš„æ”¹å˜é€ æˆå¤§çš„è¾“å‡ºè´¨é‡çš„ä¸‹é™ï¼Œé‚£å°±æ˜¯criticalçš„ç¥ç»å…ƒï¼Œåä¹‹å°±æ˜¯resilientçš„ç¥ç»å…ƒ
    - å»åˆ¤æ–­æ¯ä¸ªç¥ç»å…ƒçš„criticalityï¼Œç›´è§‚çš„ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å…¥éšæœºçš„erroråœ¨æ¯ä¸ªç¥ç»å…ƒç„¶åçœ‹å¯¹ç»“æœçš„å½±å“ï¼Œä½†æ˜¯ä¸å®é™…å•ä¸ªç¥ç»å…ƒå¯¹äºå¤§å‹ç½‘ç»œæ¥è¯´å¤ªæ¸ºå°äº†
- æœ¬èŠ‚ Present our efficient theoretical-based criticality analysis for neurons in output layer and hidden layers

- å…¬å¼æ¨å¯¼å‡ºè¡¨ç¤ºç¥ç»å…ƒçš„criticalityçš„å¼å­ï¼Œç„¶åæŒ‰ç…§criticalityæ¥æ’åˆ—criticality ranking vector

### 3.2 Approximate Artificial Neural Network Architecture
- Neurons in the same layer share the same input vector ğ‘¥, and their different weight vectors ğ‘¤s form the weight matrix between the current layer and the pervious layer
- ä½¿ç”¨å›¾ä¸‰çš„widely used ç¡¬ä»¶ç»“æ„ï¼Œæ¯ä¸ªprocessing elementï¼ˆPEï¼‰ä½œä¸ºä¸€ä¸ªç¥ç»å…ƒåŒ…æ‹¬ä¸€ç³»åˆ—ç®—æœ¯é€»è¾‘å•å…ƒå’Œlocal memoryï¼ˆLMï¼‰ï¼Œåªè¯»å–ç›¸åº”çš„weight vectorä»off-chip memoryåˆ°LM
- å› ä¸ºstreaming vector x å¯¹äºæ¯å±‚çš„ç¥ç»å…ƒéƒ½æ˜¯ä¸€æ ·çš„æ‰€ä»¥å¾—åˆ°è¿™æ ·çš„ç»“æ„ï¼ˆå›¾ä¸‰ï¼‰
- **å¾—åˆ°data transfer DT å’Œ computation workload CWçš„å…¬å¼ï¼Œæ¨å‡ºæ•°æ®å­˜å–è€—èƒ½å’Œè®¡ç®—è€—èƒ½çš„æ¯”ä¾‹å…¬ç¤º**ä¸»è¦æœ‰ä»¥ä¸‹ä¸‰ç§è¿‘ä¼¼è®¡ç®—æ–¹æ³•
    1. Memory Access Skipping
    2. Precision Scaling
    3. Approximate Arithmetic Building Blocks

### 3.3 Optimization Procedure

- å…·ä½“é—®é¢˜å°±æ˜¯åœ¨è´¨é‡ä¸‹é™çš„é™åº¦å†…ï¼Œæ±‚èƒ½é‡çš„æœ€å°æ¶ˆè€—ï¼Œå¦‚æœç¥ç»å…ƒä¹‹é—´äº’ç›¸æ²¡æœ‰è”ç³»çš„è¯ï¼Œé‚£ä¹ˆå°±æ˜¯ç®€å•çš„åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œä½†æ˜¯æ˜¾ç„¶ç¥ç»å…ƒä¹‹é—´ç›¸äº’è”ç³»ç´§å¯†ï¼Œæ‰€ä»¥é‡‡ç”¨ä¸€ç§è¿­ä»£çš„å¯å‘å¼æ–¹æ³•å»å†³å®šå“ªäº›ç¥ç»å…ƒå¯ä»¥è¿‘ä¼¼
- **å›¾å››**â€”â€”ç°æœ‰ç›¸å…³çš„ä¸€ä¸ªæ¯”è¾ƒå¤§çš„ budget for quality degradationï¼Œæ„å‘³ç€æ¯”è¾ƒå¤šçš„ç¥ç»å…ƒå¯ä»¥é™ä½è´¨é‡æ¢å–èƒ½é‡æ•ˆç‡ï¼Œéšç€æ¥è¿‘ç®—æ³•çš„æ”¶æ•›ï¼Œè¿™ä¸ªbudgetä¼šè¶Šæ¥è¶Šå°ï¼Œé‚£ä¹ˆå¯ä»¥è¿‘ä¼¼çš„ç¥ç»å…ƒä¹Ÿä¼šå˜å°‘ã€‚å› æ­¤batch size should be adaptive based on the changing quality budget
- **Algo. 1**â€”â€”çœ‹è®ºæ–‡



-----

å¾…ç»­